task: TruthfulQA
train_ratio: 0.8777

seed: 42

# MODEL
generator_model: gpt-3.5-turbo

critic_model: bert-base-cased
add_special_tokens: True

# MODE
critic_mode: classification # generation / classification
score_mode: # None / sum_logits / log_prob / neg_ppl / mean_logits

# SEARCH PARAMS
beam_size: 20
num_candidates: 20
max_length: 1
early_stopping: True
only_eval_answers: False

# QUERY_PARAMS
temperature: 1.0
frequency_penalty: 0 
presence_penalty: 0 
stop: ["\n", "\n\n", "\n\n\n"]
max_tokens: 100

# TRAINING_PARAMS
## offline warmup
offline_warmup_path: # set this to empty is offline warmup is undesired 
num_epochs_offline_warmup: 

## blackbox warmup
use_blackbox_warmup: False
num_epochs_blackbox_warmup: 
num_candidates_blackbox_warmup: 

## online finetuning
num_online_finetuning_repeat: 1

num_epochs: 30
batch_size: 64 
gradient_accumulation_steps: 1 


l2_reg_coef: 1.
energy_temp: 5.
warmup_steps: 0
learning_rate: 5.E-6
min_lr: 5.E-6
T_lr: 1000

num_negatives_for_training: 20
qa_template: "Q: <Q>\nA: <A>"

# EVALUATION
eval_blackbox: True
eval_unfinetuned: False
num_eval_rounds: 10

log_with_wandb: True

# TASK_SPECIFIC
use_dataset_negative_ans: False
